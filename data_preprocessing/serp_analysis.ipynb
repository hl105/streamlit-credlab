{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6y/w5dznchj3w9cyjt81v33hf1c0000gn/T/ipykernel_47929/2685431499.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import os\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = \"/Users/ihoonsun/Desktop/summer projects/sci/serp-analysis\"\n",
    "def get_file_paths(mainDir):\n",
    "    filePathList = []\n",
    "    for root, dir, files in os.walk(mainDir):\n",
    "        for file in files:\n",
    "            if file.endswith('html'):\n",
    "                filePath = os.path.join(root,file)\n",
    "                filePathList.append(filePath)\n",
    "    return filePathList\n",
    "\n",
    "def get_query_name(filePath):\n",
    "    return filePath.split('/')[-1].split('@')[0].split('_')[0]\n",
    "\n",
    "def get_trending_date(filePath):\n",
    "    return filePath.split('/')[-1].split('@')[1].split('_')[0]\n",
    "\n",
    "def get_collected_date(filePath):\n",
    "    return filePath.split('/')[-1].split('@')[2].split('.html')[0]\n",
    "\n",
    "def elements(search):\n",
    "    org_pos = 1\n",
    "    cmpts = []\n",
    "    for el in search:\n",
    "        parent_class = el.find_parent().get(\"class\")\n",
    "        print(parent_class)\n",
    "        if parent_class is not None and \"tF2Cxc\" not in parent_class and 'ULSxyf' not in parent_class:\n",
    "            if el is not None:\n",
    "                dom = el.find('cite')  # check if domain exists\n",
    "                link = el.find('a')['href'] if el.find('a') else None  # full link\n",
    "                title = el.find('h3').text if el.find('h3') else None  # title of result\n",
    "                bolded = [tag.text for tag in el.find_all('em') + el.find_all('b')]  # bolded words in snippet\n",
    "                if dom is not None:\n",
    "                    domain = dom.text.split()[0]\n",
    "                    dct = {'type': 'organic', 'domain': domain, 'link': link, \n",
    "                           'title': title, 'org-position': org_pos, 'bolded': bolded}\n",
    "                    org_pos += 1\n",
    "                    cmpts.append(dct)\n",
    "                nested = el.find_all(class_=\"d4rhi\")\n",
    "                if nested:\n",
    "                    for el in nested:\n",
    "                        dom = el.find('cite')  # check if domain exists\n",
    "                        if dom is not None:\n",
    "                            domain = el.find('cite').text.split()[0]  # domain\n",
    "                            link = el.find('a')['href'] if el.find('a') else None  # full link\n",
    "                            title = el.find('h3').text if el.find('h3') else None  # title of result\n",
    "                            bolded = [tag.text for tag in el.find_all('em') + el.find_all('b')]  # bolded words in snippet\n",
    "                            dct = {'type': 'organic', 'domain': domain, 'link': link, \n",
    "                                   'title': title, 'org-position': org_pos, 'bolded': bolded}\n",
    "                            cmpts.append(dct)\n",
    "                            org_pos += 1\n",
    "    return cmpts\n",
    "\n",
    "def get_file_data():\n",
    "    #filepath = os.path.join(baseDir, fileName)\n",
    "    filepath = '/Users/ihoonsun/Desktop/summer projects/sci/serp-analysis/collected@07-03-13/trending@07-03-13/Google_trending@07-03-13_collected@07-03-13.html'\n",
    "    htmlText = open(filepath, 'r', encoding=\"utf8\").read()\n",
    "    soup = BS(htmlText,'html.parser')\n",
    "    #     search = soup.find('div', id='search')\n",
    "    search = soup.find_all(class_=\"MjjYud\")\n",
    "    if len(search) > 1:\n",
    "        cmpts = elements(search)\n",
    "    if len(search) == 0:\n",
    "        search = soup.find_all(class_=\"yuRUbf\")\n",
    "        cmpts = elements(search)\n",
    "    return cmpts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 15:13:55.97 | ERROR | WebSearcher.components | Parsing Exception | 1 | img_cards\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ihoonsun/anaconda3/envs/proj2/lib/python3.12/site-packages/WebSearcher/components.py\", line 62, in parse_component\n",
      "    parsed_list = main_parser(self.elem)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import WebSearcher as ws\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.width', 120, \n",
    "              'display.max_colwidth', 40,\n",
    "              'display.max_rows', None, \n",
    "              'display.max_columns', None)\n",
    "\n",
    "filepath = '/Users/ihoonsun/Desktop/summer projects/sci/serp-analysis/collected@07-03-13/trending@07-03-13/Google_trending@07-03-13_collected@07-03-13.html'\n",
    "\n",
    "with open(filepath, 'r', encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "parsed = ws.parse_serp(soup)\n",
    "results = pd.DataFrame(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def parse_html(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        \n",
    "        results = []\n",
    "        for section in soup.find_all('div', class_='Wt5Tfe'):\n",
    "            for link in section.find_all('a', jsname='dvJQC'):\n",
    "                results.append(link.get('data-l1') + ' ' + link.get('data-l2'))\n",
    "        \n",
    "        return results\n",
    "\n",
    "file1 = '/Users/ihoonsun/Desktop/summer projects/sci/serp-analysis/collected@07-03-13/trending@07-03-13/Google_trending@07-03-13_collected@07-03-13.html'\n",
    "file2 = '/Users/ihoonsun/Desktop/summer projects/sci/serp-analysis/collected@07-03-13/trending@07-03-13/Google_trending@07-03-13_collected@07-03-13.html'\n",
    "\n",
    "results1 = parse_html(file1)\n",
    "results2 = parse_html(file2)\n",
    "\n",
    "all_results = results1 + results2\n",
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = get_file_paths(baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden Abortion First Lady 06-28-22 07-01-17\n"
     ]
    }
   ],
   "source": [
    "print(get_query_name(fileList[0]), get_trending_date(fileList[0]), get_collected_date(fileList[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c09f7722eb0a6362bfc929b0044d36c9d3fd8ae563181cdc1dd80b6b3d830d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
